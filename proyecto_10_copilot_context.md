# Proyecto 10 ‚Äî Contexto para GitHub Copilot / Modelos de IA

## Resumen del proyecto

Ajuste Din√°mico de Frecuencia (DVFS) en Sistemas Heterog√©neos CPU‚ÄìGPU mediante Aprendizaje Autom√°tico. Objetivo: dise√±ar e implementar un runtime ligero que, usando un modelo ML entrenado con m√©tricas de ejecuci√≥n, ajuste en tiempo real las frecuencias de CPU y GPU para minimizar el Energy‚ÄìDelay Product (EDP) en aplicaciones HPC h√≠bridas.

## Alcance y metas t√©cnicas

- **Plataformas objetivo**: Cluster HPC UIS con CPUs Intel Xeon (m√∫ltiples arquitecturas: Nehalem, Westmere, Haswell) y GPUs NVIDIA (Tesla M2050, Tesla K20c, GTX TITAN X). Desarrollo local en Fedora con CPU Intel.
- **Hardware detection**: Script `detect_hardware_v2.py` (Python 2.7+/3.x compatible) para auditor√≠a de hardware, capacidades de energ√≠a (RAPL/hwmon), y generaci√≥n de JSON versionado (schema 2.0).
- **Workloads de referencia**: microbenchmarks CPU (dot product, memcpy), kernels GPU (small GEMM, stencil 3D, SpMV).
- **Objetivos entregables**: scripts de benchmarking y automatizaci√≥n; dataset CSV con 100 features dise√±ados; modelos ML entrenados (Random Forest, XGBoost); runtime (C++/Python) que aplique DVFS en l√≠nea; notebooks de an√°lisis; manuscrito IMRAD.

## Estructura de archivos sugerida (repo)

```
/proyecto10/
‚îú‚îÄ data/                  # datasets CSV ordenados por fecha
‚îú‚îÄ benchmarks/
‚îÇ  ‚îú‚îÄ cpu/
‚îÇ  ‚îÇ  ‚îú‚îÄ dot.c
‚îÇ  ‚îÇ  ‚îî‚îÄ memcpy.c
‚îÇ  ‚îî‚îÄ gpu/
‚îÇ     ‚îú‚îÄ gemm.cu
‚îÇ     ‚îî‚îÄ stencil.cu
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ run_benchmark.py    # automatiza cpufreq, ejecuciones y logs
‚îÇ  ‚îú‚îÄ measure_power.py    # wrapper para RAPL, NVML, intel_gpu_top
‚îÇ  ‚îî‚îÄ generate_dataset.py
‚îú‚îÄ runtime/
‚îÇ  ‚îú‚îÄ controller.py       # inferencia ML + aplicaci√≥n de frecuencia
‚îÇ  ‚îî‚îÄ controller.cpp      # alternativa en C++ o Rust
‚îú‚îÄ models/
‚îÇ  ‚îî‚îÄ rf_model.joblib
‚îú‚îÄ notebooks/
‚îÇ  ‚îî‚îÄ analysis.ipynb
‚îî‚îÄ README.md
```

## Formato de dataset (CSV)

Campos sugeridos (columnas):
- timestamp (ISO8601)
- hostname
- cpu_model
- gpu_model
- kernel_name
- input_size
- freq_cpu_MHz
- freq_gpu_MHz
- time_s
- energy_J_cpu
- energy_J_gpu
- edp_Js
- instructions
- cycles
- ipc
- cache_misses
- l1_misses
- l2_misses
- sm_util_percent (si aplica)
- gpu_occupancy
- run_id

Unidades: frecuencias en MHz, tiempo en segundos, energ√≠a en Joules, EDP en Joules√ósegundos.

## APIs y herramientas (recomendadas)

- **CPU control**: `cpupower` / sysfs (`/sys/devices/system/cpu/cpu*/cpufreq/`)
- **CPU energy (Intel)**: RAPL (`turbostat`, `perf`, `pyRAPL`) or direct MSR via `msr-tools`
- **CPU energy (AMD)**: hwmon interface (`k10temp`, `zenpower`, `/sys/class/hwmon/`), AMD uProf para profiling avanzado
- **GPU control/medici√≥n (NVIDIA)**: `nvidia-smi`, `pynvml` (NVML API)
- **Perf profiling**: `perf stat` para ciclos, instrucciones, cache-misses, IPC, branch-misses
- **Hardware monitoring**: `/sys/class/hwmon/` para sensores de temperatura y potencia
- **Python libs**: `pynvml`, `psutil`, `pandas`, `scikit-learn`, `xgboost`, `joblib`, `optuna`, `numpy`, `matplotlib`, `seaborn`
- **Herramientas de cluster**: `numactl` (NUMA binding), `ipmitool` (BMC telemetry), `lshw`, `lspci`

## Hardware Detection (Script: detect_hardware_v2.py)

**Version:** 2.0 (Updated October 2025)

El script `detect_hardware_v2.py` es una utilidad **read-only** y **no-intrusiva** para detecci√≥n completa de hardware en cluster HPC y estaciones de desarrollo:

**Caracter√≠sticas:**
- Compatible Python 2.7+ y 3.x (CentOS 7 y Fedora)
- Detecci√≥n completa CPU/GPU/NUMA sin privilegios root
- Detecci√≥n de capacidades de energ√≠a: RAPL (Intel), hwmon (AMD)
- **Detecci√≥n avanzada AMD**: AMD uProf installation, version, MSR access, capabilities
- **GPU detection robusto**: nvidia-smi (primary) con lspci fallback para cluster con m√∫ltiples GPUs
- Detecci√≥n de sensores hwmon (temperatura, potencia)
- Sistema de advertencias y recomendaciones autom√°tico con gu√≠as AMD-espec√≠ficas
- Salida JSON versionada (schema v2.0) + reporte legible en consola
- **CLI arguments**: `--output-dir`, `--filename`, `--quiet`, `--json-only` para integraci√≥n con SLURM/PBS

**Outputs:**
- `hardware_detect_report.json`: JSON estructurado con schema v2.0
- Reporte de consola con advertencias contextuales
- GPU indexing (0-7) para multi-GPU systems

**Documentaci√≥n completa:**
- Ver `docs/HARDWARE_DETECTOR_SPEC.md` (especificaci√≥n t√©cnica completa)
- Ver `docs/AMD_PROFILING_GUIDE.md` (gu√≠a completa de profiling AMD)
- Ver `docs/DEPLOYMENT_GUIDE.md` (despliegue en cluster HPC)
- Ver `docs/ML_FEATURE_SET.md` (100 features para dataset ML)
- Ver `docs/cluster_capabilities.md` (resumen de nodos HPC disponibles)

**Cluster HPC UIS - Nodos disponibles:**
- **guane04**: 8√ó Tesla M2050 (2.6 GB), 24 CPUs, mejor para multi-GPU DVFS
- **thor**: 2√ó Tesla K20c (4.7 GB), 128 CPUs, RAPL disponible
- **felix**: 2√ó GTX TITAN X (12 GB), 64 CPUs, NUMA 4 nodos
- **yaje**: 1√ó GTX TITAN X (12 GB), 6 CPUs, single-socket test bed

**AMD-Specific Features:**
- Detecta instalaci√≥n de AMD uProf (path, version, capabilities)
- Verifica disponibilidad de MSR para profiling avanzado
- Compara hwmon (k10temp/zenpower) vs AMD uProf capabilities
- Proporciona recomendaciones espec√≠ficas por generaci√≥n (Zen2/Zen3/Zen4)

## Pipeline de experimentos (alto nivel)

1. **Detecci√≥n de hardware**: Usar `detect_hardware_v2.py` en cada nodo del cluster para auditar capacidades (CPU, GPU, RAPL, NUMA).
2. **Implementar y validar microbenchmarks** CPU/GPU con diferentes tama√±os de entrada.
3. **Automatizar barridos de frecuencia**: Scripts que var√≠en frecuencias CPU (cpufreq) y GPU (nvidia-smi) en espacio discreto.
4. **Recolectar m√©tricas completas**: 
   - Rendimiento: `perf stat` (IPC, cache-misses, branch-misses, stalls)
   - Energ√≠a: RAPL/hwmon (CPU), NVML (GPU)
   - Utilizaci√≥n: CPU/GPU utilization, temperatures, throttling
   - GPU profiling: occupancy, SM efficiency, memory bandwidth
5. **Generar dataset CSV**: 100 features por run (ver `docs/ML_FEATURE_SET.md`)
6. **Feature engineering**: Limpieza, normalizaci√≥n, interacciones, derivadas (notebook `analysis.ipynb`)
7. **Entrenamiento de modelos**: RF/XGBoost con validaci√≥n k-fold, optimizaci√≥n hiperpar√°metros (Optuna)
8. **Implementar runtime**: Inferencia ligera + APIs de control de frecuencia en C++/Python
9. **Evaluaci√≥n final**: Kernels de referencia (GEMM, stencil, SpMV), comparaci√≥n estad√≠stica EDP
10. **Documentaci√≥n**: Manuscrito IMRAD con resultados reproducibles

**Dataset objective**: 5000-10000 samples
- Frequency configs: 6 CPU √ó 6 GPU = 36 per workload
- Workloads: 5 kernels √ó 8 input sizes √ó 5 runs = 1440 base experiments

## Especificaciones para Copilot prompts (c√≥mo pedirle ayuda)

- Mantener contexto: "Proyecto10: DVFS+ML; objetivo: minimizar EDP; dataset: columnas X; target: freq_cpu, freq_gpu".
- Pedir funciones unitarias: p.ej. "Escribe funci√≥n Python que lea freq disponibles desde /sys/devices/... y devuelva lista de int MHz".
- Pedir tests: "Genera test pytest que verifique que run_benchmark.py produce un CSV con columnas esperadas".
- Pedir snippets de integraci√≥n C++/Python: PyBind11 example para invocar Python ML model desde C++ runtime.

## Criterios de reproducibilidad y buenas pr√°cticas

- Registrar commit SHA y versi√≥n del modelo en cada experimento.
- Incluir seed determinista en entrenamiento y experimentos aleatorios.
- Guardar metadatos del entorno (`lscpu`, `nvidia-smi -q`, `uname -a`) junto a cada dataset.
- Scripts con flags `--dry-run` y `--repeat N`.

## Notas de seguridad y permisos

- El proyecto requiere privilegios para cambiar frecuencias (`sudo cpupower`, `nvidia-smi -lgc`), documentar comandos exactos y pedir permiso de administrador en servidores.
- En cluster compartido, coordinar cambios de frecuencia con administrador y respetar pol√≠ticas de uso.
- **Hardware detection es read-only**: No requiere privilegios, graceful degradation cuando RAPL/MSR no es accesible.
- Scripts de deployment: `scripts/deploy_to_cluster.sh` automatiza transferencia y validaci√≥n en nodos remotos.
- Git workflow: Conventional commits (feat/fix/docs/chore) con mensajes detallados.

---

## Progreso actual del proyecto (October 2025)

### ‚úÖ Completado
- [x] Hardware detection v2.0 con soporte AMD completo, GPU multi-device, CLI arguments
- [x] Test suite comprehensivo (23 tests passing)
- [x] Documentaci√≥n t√©cnica (1300+ l√≠neas): HARDWARE_DETECTOR_SPEC, AMD_PROFILING_GUIDE, DEPLOYMENT_GUIDE
- [x] Feature set para ML: 100 features definidos con rationale y estrategia de colecci√≥n
- [x] Caracterizaci√≥n de nodos del cluster HPC UIS (4 nodos documentados)
- [x] Scripts de deployment automatizado para cluster

### üîÑ En progreso
- [ ] Implementaci√≥n de microbenchmarks CPU/GPU
- [ ] Scripts de automatizaci√≥n de experimentos (run_benchmark.py)
- [ ] Colecci√≥n de dataset inicial (MVP: 1000 samples)
- [ ] An√°lisis exploratorio de datos

### üìã Pendiente
- [ ] Entrenamiento de modelos iniciales (RF/XGBoost)
- [ ] Runtime de inferencia y control DVFS
- [ ] Evaluaci√≥n en kernels de referencia
- [ ] Manuscrito IMRAD

---

*Este archivo sirve como punto de partida para prompts a Copilot y otros modelos de IA. Mantenerlo actualizado conforme evolucionen las pruebas y el entorno experimental.*

